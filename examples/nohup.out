/home/kliem/miniconda3/envs/penv/lib/python3.10/site-packages/pygame/pkgdata.py:25: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.
  from pkg_resources import resource_stream, resource_exists
Config Dict:  1.0
Warning! Config variable 'untag_radius' not recognized (it will have no effect).
Please consult config.py for variable names.

Warning! Config variable 'tag_speed_frac' not recognized (it will have no effect).
Please consult config.py for variable names.

Warning! Config variable 'tag_probability' not recognized (it will have no effect).
Please consult config.py for variable names.

Warning! Config variable 'power_play_percentage' not recognized (it will have no effect).
Please consult config.py for variable names.

Config Dict:  1.0
Warning! Config variable 'untag_radius' not recognized (it will have no effect).
Please consult config.py for variable names.

Warning! Config variable 'tag_speed_frac' not recognized (it will have no effect).
Please consult config.py for variable names.

Warning! Config variable 'tag_probability' not recognized (it will have no effect).
Please consult config.py for variable names.

Warning! Config variable 'power_play_percentage' not recognized (it will have no effect).
Please consult config.py for variable names.

Iteration 1/208 | Iteration Elapsed 76.76743054389954 | Average: {'agent_0': tensor(0.), 'agent_1': tensor(0.), 'agent_2': tensor(0.), 'agent_3': tensor(0.), 'agent_4': tensor(0.), 'agent_5': tensor(0.)} | SPS 312.61596765046824 | Policy Update 53.93098330497742
Iteration 2/208 | Iteration Elapsed 77.41393852233887 | Average: {'agent_0': tensor(0.), 'agent_1': tensor(0.), 'agent_2': tensor(0.), 'agent_3': tensor(0.), 'agent_4': tensor(0.), 'agent_5': tensor(0.)} | SPS 310.0175789856873 | Policy Update 54.55840086936951
Iteration 3/208 | Iteration Elapsed 75.56357479095459 | Average: {'agent_0': tensor(0.), 'agent_1': tensor(0.), 'agent_2': tensor(0.), 'agent_3': tensor(0.), 'agent_4': tensor(0.), 'agent_5': tensor(0.)} | SPS 317.6095412486744 | Policy Update 53.6592059135437
Iteration 4/208 | Iteration Elapsed 76.68768048286438 | Average: {'agent_0': tensor(0.), 'agent_1': tensor(0.), 'agent_2': tensor(0.), 'agent_3': tensor(0.), 'agent_4': tensor(0.), 'agent_5': tensor(0.)} | SPS 312.9534867295745 | Policy Update 54.505311727523804
Iteration 5/208 | Iteration Elapsed 76.25071954727173 | Average: {'agent_0': tensor(0.), 'agent_1': tensor(0.), 'agent_2': tensor(0.), 'agent_3': tensor(0.), 'agent_4': tensor(0.), 'agent_5': tensor(0.)} | SPS 314.7473401867442 | Policy Update 54.222548484802246
Iteration 6/208 | Iteration Elapsed 74.45172047615051 | Average: {'agent_0': tensor(0.), 'agent_1': tensor(0.), 'agent_2': tensor(0.), 'agent_3': tensor(0.), 'agent_4': tensor(0.), 'agent_5': tensor(0.)} | SPS 322.3529300023669 | Policy Update 52.8745322227478
Iteration 7/208 | Iteration Elapsed 75.58524966239929 | Average: {'agent_0': tensor(0.), 'agent_1': tensor(0.), 'agent_2': tensor(0.), 'agent_3': tensor(0.), 'agent_4': tensor(0.), 'agent_5': tensor(0.)} | SPS 317.5183542688816 | Policy Update 54.115957260131836
Iteration 8/208 | Iteration Elapsed 75.1796772480011 | Average: {'agent_0': tensor(0.), 'agent_1': tensor(0.), 'agent_2': tensor(0.), 'agent_3': tensor(0.), 'agent_4': tensor(0.), 'agent_5': tensor(0.)} | SPS 319.23147459657434 | Policy Update 53.27721405029297
Iteration 9/208 | Iteration Elapsed 76.17937731742859 | Average: {'agent_0': tensor(0.), 'agent_1': tensor(0.), 'agent_2': tensor(0.), 'agent_3': tensor(0.), 'agent_4': tensor(0.), 'agent_5': tensor(0.)} | SPS 315.0424081205897 | Policy Update 53.64871001243591
Iteration 10/208 | Iteration Elapsed 75.50393104553223 | Average: {'agent_0': tensor(0.), 'agent_1': tensor(0.), 'agent_2': tensor(0.), 'agent_3': tensor(0.), 'agent_4': tensor(0.), 'agent_5': tensor(0.)} | SPS 317.86042139870244 | Policy Update 53.635623931884766
Iteration 11/208 | Iteration Elapsed 74.64230823516846 | Average: {'agent_0': tensor(0.), 'agent_1': tensor(0.), 'agent_2': tensor(0.), 'agent_3': tensor(0.), 'agent_4': tensor(0.), 'agent_5': tensor(0.)} | SPS 321.5298139330584 | Policy Update 53.02539682388306
Iteration 12/208 | Iteration Elapsed 75.82621932029724 | Average: {'agent_0': tensor(0.), 'agent_1': tensor(0.), 'agent_2': tensor(0.), 'agent_3': tensor(0.), 'agent_4': tensor(0.), 'agent_5': tensor(0.)} | SPS 316.5097357278977 | Policy Update 54.02125573158264
Iteration 13/208 | Iteration Elapsed 74.9286880493164 | Average: {'agent_0': tensor(0.), 'agent_1': tensor(0.), 'agent_2': tensor(0.), 'agent_3': tensor(0.), 'agent_4': tensor(0.), 'agent_5': tensor(0.)} | SPS 320.3007166969571 | Policy Update 53.275782108306885
Iteration 14/208 | Iteration Elapsed 75.85967254638672 | Average: {'agent_0': tensor(0.), 'agent_1': tensor(0.), 'agent_2': tensor(0.), 'agent_3': tensor(0.), 'agent_4': tensor(0.), 'agent_5': tensor(0.)} | SPS 316.3694263808564 | Policy Update 53.768741846084595
Iteration 15/208 | Iteration Elapsed 75.48771739006042 | Average: {'agent_0': tensor(0.), 'agent_1': tensor(0.), 'agent_2': tensor(0.), 'agent_3': tensor(0.), 'agent_4': tensor(0.), 'agent_5': tensor(0.)} | SPS 317.9281039209965 | Policy Update 53.45825433731079
Iteration 16/208 | Iteration Elapsed 76.60082912445068 | Average: {'agent_0': tensor(0.), 'agent_1': tensor(0.), 'agent_2': tensor(0.), 'agent_3': tensor(0.), 'agent_4': tensor(0.), 'agent_5': tensor(0.)} | SPS 313.30762659851456 | Policy Update 54.55426263809204
Iteration 17/208 | Iteration Elapsed 76.12152147293091 | Average: {'agent_0': tensor(0.), 'agent_1': tensor(0.), 'agent_2': tensor(0.), 'agent_3': tensor(0.), 'agent_4': tensor(0.), 'agent_5': tensor(0.)} | SPS 315.27222848321287 | Policy Update 54.28595423698425
Iteration 18/208 | Iteration Elapsed 77.87087845802307 | Average: {'agent_0': tensor(0.), 'agent_1': tensor(0.), 'agent_2': tensor(0.), 'agent_3': tensor(0.), 'agent_4': tensor(0.), 'agent_5': tensor(0.)} | SPS 308.1982744137648 | Policy Update 54.17681050300598
Iteration 19/208 | Iteration Elapsed 75.39524245262146 | Average: {'agent_0': tensor(0.), 'agent_1': tensor(0.), 'agent_2': tensor(0.), 'agent_3': tensor(0.), 'agent_4': tensor(0.), 'agent_5': tensor(0.)} | SPS 318.3182690334566 | Policy Update 53.968053102493286
Iteration 20/208 | Iteration Elapsed 76.39635896682739 | Average: {'agent_0': tensor(0.), 'agent_1': tensor(0.), 'agent_2': tensor(0.), 'agent_3': tensor(0.), 'agent_4': tensor(0.), 'agent_5': tensor(0.)} | SPS 314.14735416509615 | Policy Update 53.5307092666626
Iteration 21/208 | Iteration Elapsed 75.7541434764862 | Average: {'agent_0': tensor(0.), 'agent_1': tensor(0.), 'agent_2': tensor(0.), 'agent_3': tensor(0.), 'agent_4': tensor(0.), 'agent_5': tensor(0.)} | SPS 316.8099106124581 | Policy Update 54.10918378829956
Iteration 22/208 | Iteration Elapsed 77.47838950157166 | Average: {'agent_0': tensor(0.), 'agent_1': tensor(0.), 'agent_2': tensor(0.), 'agent_3': tensor(0.), 'agent_4': tensor(0.), 'agent_5': tensor(0.)} | SPS 309.7601313748604 | Policy Update 54.742485761642456
Iteration 23/208 | Iteration Elapsed 77.29048037528992 | Average: {'agent_0': tensor(0.), 'agent_1': tensor(0.), 'agent_2': tensor(0.), 'agent_3': tensor(0.), 'agent_4': tensor(0.), 'agent_5': tensor(0.)} | SPS 310.513212364193 | Policy Update 54.733768701553345
Iteration 24/208 | Iteration Elapsed 75.60640335083008 | Average: {'agent_0': tensor(0.), 'agent_1': tensor(0.), 'agent_2': tensor(0.), 'agent_3': tensor(0.), 'agent_4': tensor(0.), 'agent_5': tensor(0.)} | SPS 317.42970504013874 | Policy Update 54.160879611968994
Iteration 25/208 | Iteration Elapsed 76.05205297470093 | Average: {'agent_0': tensor(0.), 'agent_1': tensor(0.), 'agent_2': tensor(0.), 'agent_3': tensor(0.), 'agent_4': tensor(0.), 'agent_5': tensor(0.)} | SPS 315.5701238748676 | Policy Update 54.09468650817871
Iteration 26/208 | Iteration Elapsed 75.5892858505249 | Average: {'agent_0': tensor(0.), 'agent_1': tensor(0.), 'agent_2': tensor(0.), 'agent_3': tensor(0.), 'agent_4': tensor(0.), 'agent_5': tensor(0.)} | SPS 317.5012479557347 | Policy Update 54.08501100540161
Iteration 27/208 | Iteration Elapsed 75.24577045440674 | Average: {'agent_0': tensor(0.), 'agent_1': tensor(0.), 'agent_2': tensor(0.), 'agent_3': tensor(0.), 'agent_4': tensor(0.), 'agent_5': tensor(0.)} | SPS 318.9507438244828 | Policy Update 53.835888147354126
Iteration 28/208 | Iteration Elapsed 75.55777359008789 | Average: {'agent_0': tensor(0.), 'agent_1': tensor(0.), 'agent_2': tensor(0.), 'agent_3': tensor(0.), 'agent_4': tensor(0.), 'agent_5': tensor(0.)} | SPS 317.6329803560721 | Policy Update 53.7800087928772
Iteration 29/208 | Iteration Elapsed 76.9076681137085 | Average: {'agent_0': tensor(0.), 'agent_1': tensor(0.), 'agent_2': tensor(0.), 'agent_3': tensor(0.), 'agent_4': tensor(0.), 'agent_5': tensor(0.)} | SPS 312.057503401737 | Policy Update 54.15376424789429
Iteration 30/208 | Iteration Elapsed 75.24623608589172 | Average: {'agent_0': tensor(0.), 'agent_1': tensor(0.), 'agent_2': tensor(0.), 'agent_3': tensor(0.), 'agent_4': tensor(0.), 'agent_5': tensor(0.)} | SPS 318.9382897682098 | Policy Update 52.94575500488281
Iteration 31/208 | Iteration Elapsed 76.33947205543518 | Average: {'agent_0': tensor(0.), 'agent_1': tensor(0.), 'agent_2': tensor(0.), 'agent_3': tensor(0.), 'agent_4': tensor(0.), 'agent_5': tensor(0.)} | SPS 314.3812956162169 | Policy Update 54.09242391586304
/home/kliem/miniconda3/envs/penv/lib/python3.10/multiprocessing/resource_tracker.py:224: UserWarning: resource_tracker: There appear to be 30 leaked shared_memory objects to clean up at shutdown
  warnings.warn('resource_tracker: There appear to be %d '
